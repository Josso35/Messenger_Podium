{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "insured-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import fr_core_news_sm\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#nltk.download()\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "stunning-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list=['©',',','?','.','!','ã',' ','\"','','ã§a','\\n','(','etre','avoir','cela','caest','faire']\n",
    "final_stopwords_list_1 = stopwords.words('english') + stopwords.words('french') + my_list\n",
    "nlp = fr_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "urban-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coding problem from Facebook menssenger side\n",
    "def parse_obj(obj):\n",
    "    for key in obj:\n",
    "        if isinstance(obj[key], str):\n",
    "            obj[key] = obj[key].encode('latin_1').decode('utf-8')\n",
    "        elif isinstance(obj[key], list):\n",
    "            obj[key] = list(map(lambda x: x if type(x) != str else x.encode('latin_1').decode('utf-8'), obj[key]))\n",
    "        pass\n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "def load_all_messages(path):\n",
    "    # Open first the first message\n",
    "    file = open(path + 'message_1.json')\n",
    "    \n",
    "    #Here we have the decoder from messnenger\n",
    "    data = json.load(file, object_hook=parse_obj)\n",
    "    \n",
    "    #\n",
    "    df = pd.json_normalize(data['messages'])\n",
    "    \n",
    "    #Then open the other ones and append them\n",
    "    #Would need to change that to apply to every number of files needed\n",
    "    for i in np.arange(2,6) : \n",
    "        file = open(path + 'message_'+str(i)+'.json', encoding='utf8')\n",
    "        data = json.load(file)\n",
    "        df_temp = pd.json_normalize(data['messages'])\n",
    "        df=df.append(df_temp)\n",
    "    return (df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "controlled-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    #We want a usable time stamp\n",
    "    df['date_time']=pd.to_datetime(df['timestamp_ms'], unit='ms') \n",
    "    \n",
    "    #Way easier to work with lower cases for text\n",
    "    df['content']=df['content'].str.lower()\n",
    "    \n",
    "    #Let's not work first with every data --> Only text\n",
    "    df.drop(columns=['timestamp_ms','gifs','is_unsent','photos','type','videos','audio_files','sticker.uri',\n",
    "                     'call_duration','share.link','share.share_text','users','files'],inplace=True)\n",
    "\n",
    "    df['year']=df['date_time'].dt.year\n",
    "    #df=df[df['year']==2021]\n",
    "    \n",
    "    #We can exclude some non participing people\n",
    "    df=df[~df['sender_name'].isin(['ThoJean Delavega','Paul Foulonneau','Harry Hrr','Maximilien Waeters'])]\n",
    "    \n",
    "    df['content']=df.content.fillna('')\n",
    "    #df=df[~df['content'].isna()].reset_index()\n",
    "    \n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "scheduled-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_lemma ( df): \n",
    "    df['parsed_content'] = df['content'].apply(lambda x: [y.lemma_ for y in  nlp(x)])\n",
    "    temmenized=df.explode('parsed_content')[['sender_name','parsed_content']]\n",
    "    temmenized['parsed_content']=temmenized['parsed_content'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    \n",
    "    temmenized=temmenized[~(temmenized['parsed_content'].isin(final_stopwords_list_1+my_list))]\n",
    "    temmenized['nb_use']=1\n",
    "    return(temmenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "altered-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_information( df): \n",
    "    #number of word per message\n",
    "    df['word_number'] = df['parsed_content'].apply(lambda x: len(x))\n",
    "    \n",
    "    #if the next message same sender =1\n",
    "    df['answered_himself']=df.sender_name.eq(df.sender_name.shift())\n",
    "    \n",
    "    #number of reaction\n",
    "    df['reactions']=df.reactions.fillna('')\n",
    "    df['reaction_number'] = df['reactions'].apply(lambda x: len(x))\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "interracial-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_sender(df):\n",
    "    df['is_message']=1\n",
    "    df['has_reac']=df['reaction_number'] >0\n",
    "    df_grouped=df.groupby('sender_name').agg({'word_number': ['sum', 'max','mean','median'], \n",
    "                                   'answered_himself':['sum','mean'],\n",
    "                                   'reaction_number':['sum','mean'],\n",
    "                                    'has_reac':['sum','mean'],\n",
    "                                   'is_message':['count']})\n",
    "    return(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cutting-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis.josso\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "path = \"../0. Data/\"\n",
    "df=load_all_messages(path)\n",
    "df=clean_data(df)\n",
    "temmenized= token_lemma ( df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "flexible-entry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis.josso\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "df_2021=df[df['year']==2021]\n",
    "df_2021= add_information( df_2021)\n",
    "df_grouped=groupby_sender(df_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "approximate-narrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">word_number</th>\n",
       "      <th colspan=\"2\" halign=\"left\">answered_himself</th>\n",
       "      <th colspan=\"2\" halign=\"left\">reaction_number</th>\n",
       "      <th colspan=\"2\" halign=\"left\">has_reac</th>\n",
       "      <th>is_message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sender_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adrien Goutard</th>\n",
       "      <td>1902</td>\n",
       "      <td>48</td>\n",
       "      <td>7.231939</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>155</td>\n",
       "      <td>0.589354</td>\n",
       "      <td>116</td>\n",
       "      <td>0.441065</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alex Dns</th>\n",
       "      <td>14638</td>\n",
       "      <td>423</td>\n",
       "      <td>9.419562</td>\n",
       "      <td>7.0</td>\n",
       "      <td>625</td>\n",
       "      <td>0.402188</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.754183</td>\n",
       "      <td>790</td>\n",
       "      <td>0.508366</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexandre Durand</th>\n",
       "      <td>465</td>\n",
       "      <td>35</td>\n",
       "      <td>7.622951</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>31</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>20</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antoine Gilles</th>\n",
       "      <td>953</td>\n",
       "      <td>80</td>\n",
       "      <td>5.919255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>73</td>\n",
       "      <td>0.453416</td>\n",
       "      <td>50</td>\n",
       "      <td>0.310559</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antoine Hamon</th>\n",
       "      <td>11307</td>\n",
       "      <td>148</td>\n",
       "      <td>4.963565</td>\n",
       "      <td>4.0</td>\n",
       "      <td>938</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>639</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>519</td>\n",
       "      <td>0.227831</td>\n",
       "      <td>2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arthur de Saint-Pierre</th>\n",
       "      <td>6074</td>\n",
       "      <td>167</td>\n",
       "      <td>9.344615</td>\n",
       "      <td>8.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.124615</td>\n",
       "      <td>393</td>\n",
       "      <td>0.604615</td>\n",
       "      <td>274</td>\n",
       "      <td>0.421538</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louis Jss</th>\n",
       "      <td>20242</td>\n",
       "      <td>103</td>\n",
       "      <td>8.019810</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.402536</td>\n",
       "      <td>1295</td>\n",
       "      <td>0.513074</td>\n",
       "      <td>937</td>\n",
       "      <td>0.371236</td>\n",
       "      <td>2524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robin Goutard</th>\n",
       "      <td>23688</td>\n",
       "      <td>159</td>\n",
       "      <td>7.043711</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1285</td>\n",
       "      <td>0.382099</td>\n",
       "      <td>931</td>\n",
       "      <td>0.276836</td>\n",
       "      <td>758</td>\n",
       "      <td>0.225394</td>\n",
       "      <td>3363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thomas Liberge</th>\n",
       "      <td>9424</td>\n",
       "      <td>119</td>\n",
       "      <td>6.044901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>540</td>\n",
       "      <td>0.346376</td>\n",
       "      <td>825</td>\n",
       "      <td>0.529185</td>\n",
       "      <td>553</td>\n",
       "      <td>0.354715</td>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       word_number                       answered_himself  \\\n",
       "                               sum  max      mean median              sum   \n",
       "sender_name                                                                 \n",
       "Adrien Goutard                1902   48  7.231939    6.0               32   \n",
       "Alex Dns                     14638  423  9.419562    7.0              625   \n",
       "Alexandre Durand               465   35  7.622951    7.0               13   \n",
       "Antoine Gilles                 953   80  5.919255    5.0               35   \n",
       "Antoine Hamon                11307  148  4.963565    4.0              938   \n",
       "Arthur de Saint-Pierre        6074  167  9.344615    8.0               81   \n",
       "Louis Jss                    20242  103  8.019810    5.0             1016   \n",
       "Robin Goutard                23688  159  7.043711    5.0             1285   \n",
       "Thomas Liberge                9424  119  6.044901    5.0              540   \n",
       "\n",
       "                                 reaction_number           has_reac            \\\n",
       "                            mean             sum      mean      sum      mean   \n",
       "sender_name                                                                     \n",
       "Adrien Goutard          0.121673             155  0.589354      116  0.441065   \n",
       "Alex Dns                0.402188            1172  0.754183      790  0.508366   \n",
       "Alexandre Durand        0.213115              31  0.508197       20  0.327869   \n",
       "Antoine Gilles          0.217391              73  0.453416       50  0.310559   \n",
       "Antoine Hamon           0.411765             639  0.280509      519  0.227831   \n",
       "Arthur de Saint-Pierre  0.124615             393  0.604615      274  0.421538   \n",
       "Louis Jss               0.402536            1295  0.513074      937  0.371236   \n",
       "Robin Goutard           0.382099             931  0.276836      758  0.225394   \n",
       "Thomas Liberge          0.346376             825  0.529185      553  0.354715   \n",
       "\n",
       "                       is_message  \n",
       "                            count  \n",
       "sender_name                        \n",
       "Adrien Goutard                263  \n",
       "Alex Dns                     1554  \n",
       "Alexandre Durand               61  \n",
       "Antoine Gilles                161  \n",
       "Antoine Hamon                2278  \n",
       "Arthur de Saint-Pierre        650  \n",
       "Louis Jss                    2524  \n",
       "Robin Goutard                3363  \n",
       "Thomas Liberge               1559  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "transparent-archives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_name</th>\n",
       "      <th>reactions</th>\n",
       "      <th>content</th>\n",
       "      <th>date_time</th>\n",
       "      <th>year</th>\n",
       "      <th>parsed_content</th>\n",
       "      <th>word_number</th>\n",
       "      <th>answered_himself</th>\n",
       "      <th>reaction_number</th>\n",
       "      <th>is_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>Robin Goutard</td>\n",
       "      <td></td>\n",
       "      <td>1/ on pense faire les courses jeudi histoire d...</td>\n",
       "      <td>2021-12-27 20:53:57.183</td>\n",
       "      <td>2021</td>\n",
       "      <td>[1/, on, pense, faire, le, course, jeudi, hist...</td>\n",
       "      <td>159</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sender_name reactions  \\\n",
       "1215  Robin Goutard             \n",
       "\n",
       "                                                content  \\\n",
       "1215  1/ on pense faire les courses jeudi histoire d...   \n",
       "\n",
       "                   date_time  year  \\\n",
       "1215 2021-12-27 20:53:57.183  2021   \n",
       "\n",
       "                                         parsed_content  word_number  \\\n",
       "1215  [1/, on, pense, faire, le, course, jeudi, hist...          159   \n",
       "\n",
       "      answered_himself  reaction_number  is_message  \n",
       "1215              True                0           1  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2021[df_2021['word_number']==159]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-dating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
