{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "single-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import fr_core_news_sm\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "economic-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = \"../0. Data/\"\n",
    "\n",
    "\n",
    "def parse_obj(obj):\n",
    "    for key in obj:\n",
    "        if isinstance(obj[key], str):\n",
    "            obj[key] = obj[key].encode('latin_1').decode('utf-8')\n",
    "        elif isinstance(obj[key], list):\n",
    "            obj[key] = list(map(lambda x: x if type(x) != str else x.encode('latin_1').decode('utf-8'), obj[key]))\n",
    "        pass\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acoustic-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(fd + 'message_1.json')\n",
    "data = json.load(file, object_hook=parse_obj)\n",
    "df = pd.json_normalize(data['messages'])\n",
    "for i in np.arange(2,6) : \n",
    "    file = open(fd + 'message_'+str(i)+'.json', encoding='utf8')\n",
    "    data = json.load(file)\n",
    "    df_temp = pd.json_normalize(data['messages'])\n",
    "    df=df.append(df_temp)\n",
    "    \n",
    "\n",
    "df['date_time']=pd.to_datetime(df['timestamp_ms'], unit='ms') \n",
    "df['content']=df['content'].str.lower()\n",
    "df.drop(columns=['timestamp_ms','gifs','is_unsent','photos','type','videos','audio_files','sticker.uri',\n",
    "                 'call_duration','share.link','share.share_text','users','files'],inplace=True)\n",
    "\n",
    "df['year']=df['date_time'].dt.year\n",
    "df=df[df['year']==2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "funky-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df['content'].isna()].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "double-fabric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sender_name</th>\n",
       "      <th>reactions</th>\n",
       "      <th>content</th>\n",
       "      <th>date_time</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>7609</td>\n",
       "      <td>Robin Goutard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bi√®re en ville putain il fait beau ahlalaaaa</td>\n",
       "      <td>2021-05-21 12:43:55.984</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>3751</td>\n",
       "      <td>Thomas Liberge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l'ex d'harry</td>\n",
       "      <td>2021-08-24 11:23:51.173</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>5733</td>\n",
       "      <td>Alex Dns</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan mais quelle soir√©e de merde</td>\n",
       "      <td>2021-06-28 22:20:33.718</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9001</th>\n",
       "      <td>1593</td>\n",
       "      <td>Robin Goutard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aucune chance ahahah</td>\n",
       "      <td>2021-02-26 10:17:22.143</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>5556</td>\n",
       "      <td>Alex Dns</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d√©cid√©ment c'est vraiment la f√™te en ce moment</td>\n",
       "      <td>2021-07-06 06:40:37.873</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     sender_name reactions  \\\n",
       "5663   7609   Robin Goutard       NaN   \n",
       "2381   3751  Thomas Liberge       NaN   \n",
       "4034   5733        Alex Dns       NaN   \n",
       "9001   1593   Robin Goutard       NaN   \n",
       "3899   5556        Alex Dns       NaN   \n",
       "\n",
       "                                             content               date_time  \\\n",
       "5663    bi√®re en ville putain il fait beau ahlalaaaa 2021-05-21 12:43:55.984   \n",
       "2381                                    l'ex d'harry 2021-08-24 11:23:51.173   \n",
       "4034                 nan mais quelle soir√©e de merde 2021-06-28 22:20:33.718   \n",
       "9001                            aucune chance ahahah 2021-02-26 10:17:22.143   \n",
       "3899  d√©cid√©ment c'est vraiment la f√™te en ce moment 2021-07-06 06:40:37.873   \n",
       "\n",
       "      year  \n",
       "5663  2021  \n",
       "2381  2021  \n",
       "4034  2021  \n",
       "9001  2021  \n",
       "3899  2021  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-findings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "stone-painting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db18dc20ee334394b0fe4b3e63717b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = fr_core_news_sm.load()\n",
    "\n",
    "temmenized = pd.DataFrame(columns=['sender_name','stem'])\n",
    "for i in tqdm(np.arange(df.shape[0]-1)) :\n",
    "    doc = nlp(df['content'][i])\n",
    "    for token in doc:\n",
    "        dict = {'sender_name': df['sender_name'][i], 'stem':token.lemma_}\n",
    "        temmenized=temmenized.append(dict, ignore_index = True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "worldwide-mixer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temmenized_root=temmenized[~temmenized['stem'].isin([fr_stop,'.','le','de','√™tre','je','avoir','ce','un','!','?',',','pas',\n",
    "                                                     'en','on','et','que','cela','¬©','haha','il','ü§£','ahah','√†','pour','te','c‚Äô',\n",
    "                                                     'faire','mais','sur','aller','tu','mon','qui','√£','avec','au','vous',\n",
    "                                                    ';)','tout','y','plus','j‚Äô','dans','bon','me',')','(','moi','se','...','^^',\n",
    "                                                    'non'])]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "portuguese-anthony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sender_name  stem   \n",
       "Alex Dns     bien       77\n",
       "             si         61\n",
       "             comme      58\n",
       "             pouvoir    54\n",
       "             lui        49\n",
       "             dire       48\n",
       "             petit      48\n",
       "             voir       44\n",
       "             ¬†          42\n",
       "             \"          42\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temmenized_root[temmenized_root['sender_name']=='Alex Dns'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "studied-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'abord',\n",
       " 'afin',\n",
       " 'ah',\n",
       " 'ai',\n",
       " 'aie',\n",
       " 'ainsi',\n",
       " 'ait',\n",
       " 'allaient',\n",
       " 'allons',\n",
       " 'alors',\n",
       " 'anterieur',\n",
       " 'anterieure',\n",
       " 'anterieures',\n",
       " 'ant√©rieur',\n",
       " 'ant√©rieure',\n",
       " 'ant√©rieures',\n",
       " 'apres',\n",
       " 'apr√®s',\n",
       " 'as',\n",
       " 'assez',\n",
       " 'attendu',\n",
       " 'au',\n",
       " 'aupres',\n",
       " 'auquel',\n",
       " 'aura',\n",
       " 'auraient',\n",
       " 'aurait',\n",
       " 'auront',\n",
       " 'aussi',\n",
       " 'autre',\n",
       " 'autrement',\n",
       " 'autres',\n",
       " 'autrui',\n",
       " 'aux',\n",
       " 'auxquelles',\n",
       " 'auxquels',\n",
       " 'avaient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avant',\n",
       " 'avec',\n",
       " 'avoir',\n",
       " 'avons',\n",
       " 'ayant',\n",
       " 'bas',\n",
       " 'basee',\n",
       " 'bat',\n",
       " \"c'\",\n",
       " 'car',\n",
       " 'ce',\n",
       " 'ceci',\n",
       " 'cela',\n",
       " 'celle',\n",
       " 'celle-ci',\n",
       " 'celle-la',\n",
       " 'celle-l√†',\n",
       " 'celles',\n",
       " 'celles-ci',\n",
       " 'celles-la',\n",
       " 'celles-l√†',\n",
       " 'celui',\n",
       " 'celui-ci',\n",
       " 'celui-la',\n",
       " 'celui-l√†',\n",
       " 'cent',\n",
       " 'cependant',\n",
       " 'certain',\n",
       " 'certaine',\n",
       " 'certaines',\n",
       " 'certains',\n",
       " 'certes',\n",
       " 'ces',\n",
       " 'cet',\n",
       " 'cette',\n",
       " 'ceux',\n",
       " 'ceux-ci',\n",
       " 'ceux-l√†',\n",
       " 'chacun',\n",
       " 'chacune',\n",
       " 'chaque',\n",
       " 'chez',\n",
       " 'ci',\n",
       " 'cinq',\n",
       " 'cinquantaine',\n",
       " 'cinquante',\n",
       " 'cinquanti√®me',\n",
       " 'cinqui√®me',\n",
       " 'combien',\n",
       " 'comme',\n",
       " 'comment',\n",
       " 'compris',\n",
       " 'concernant',\n",
       " 'c‚Äô',\n",
       " \"d'\",\n",
       " 'da',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'debout',\n",
       " 'dedans',\n",
       " 'dehors',\n",
       " 'deja',\n",
       " 'dej√†',\n",
       " 'del√†',\n",
       " 'depuis',\n",
       " 'derriere',\n",
       " 'derri√®re',\n",
       " 'des',\n",
       " 'desormais',\n",
       " 'desquelles',\n",
       " 'desquels',\n",
       " 'dessous',\n",
       " 'dessus',\n",
       " 'deux',\n",
       " 'deuxi√®me',\n",
       " 'deuxi√®mement',\n",
       " 'devant',\n",
       " 'devers',\n",
       " 'devra',\n",
       " 'different',\n",
       " 'differente',\n",
       " 'differentes',\n",
       " 'differents',\n",
       " 'diff√©rent',\n",
       " 'diff√©rente',\n",
       " 'diff√©rentes',\n",
       " 'diff√©rents',\n",
       " 'dire',\n",
       " 'directe',\n",
       " 'directement',\n",
       " 'dit',\n",
       " 'dite',\n",
       " 'dits',\n",
       " 'divers',\n",
       " 'diverse',\n",
       " 'diverses',\n",
       " 'dix',\n",
       " 'dix-huit',\n",
       " 'dix-neuf',\n",
       " 'dix-sept',\n",
       " 'dixi√®me',\n",
       " 'doit',\n",
       " 'doivent',\n",
       " 'donc',\n",
       " 'dont',\n",
       " 'douze',\n",
       " 'douzi√®me',\n",
       " 'du',\n",
       " 'duquel',\n",
       " 'durant',\n",
       " 'd√®s',\n",
       " 'd√©ja',\n",
       " 'd√©j√†',\n",
       " 'd√©sormais',\n",
       " 'd‚Äô',\n",
       " 'effet',\n",
       " 'egalement',\n",
       " 'eh',\n",
       " 'elle',\n",
       " 'elle-meme',\n",
       " 'elle-m√™me',\n",
       " 'elles',\n",
       " 'elles-memes',\n",
       " 'elles-m√™mes',\n",
       " 'en',\n",
       " 'encore',\n",
       " 'enfin',\n",
       " 'entre',\n",
       " 'envers',\n",
       " 'environ',\n",
       " 'es',\n",
       " 'est',\n",
       " 'et',\n",
       " 'etaient',\n",
       " 'etais',\n",
       " 'etait',\n",
       " 'etant',\n",
       " 'etc',\n",
       " 'etre',\n",
       " 'eu',\n",
       " 'eux',\n",
       " 'eux-m√™mes',\n",
       " 'exactement',\n",
       " 'except√©',\n",
       " 'facon',\n",
       " 'fais',\n",
       " 'faisaient',\n",
       " 'faisant',\n",
       " 'fait',\n",
       " 'fa√ßon',\n",
       " 'feront',\n",
       " 'font',\n",
       " 'gens',\n",
       " 'ha',\n",
       " 'hem',\n",
       " 'hep',\n",
       " 'hi',\n",
       " 'ho',\n",
       " 'hormis',\n",
       " 'hors',\n",
       " 'hou',\n",
       " 'houp',\n",
       " 'hue',\n",
       " 'hui',\n",
       " 'huit',\n",
       " 'huiti√®me',\n",
       " 'h√©',\n",
       " 'i',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'importe',\n",
       " \"j'\",\n",
       " 'je',\n",
       " 'jusqu',\n",
       " 'jusque',\n",
       " 'juste',\n",
       " 'j‚Äô',\n",
       " \"l'\",\n",
       " 'la',\n",
       " 'laisser',\n",
       " 'laquelle',\n",
       " 'le',\n",
       " 'lequel',\n",
       " 'les',\n",
       " 'lesquelles',\n",
       " 'lesquels',\n",
       " 'leur',\n",
       " 'leurs',\n",
       " 'longtemps',\n",
       " 'lors',\n",
       " 'lorsque',\n",
       " 'lui',\n",
       " 'lui-meme',\n",
       " 'lui-m√™me',\n",
       " 'l√†',\n",
       " 'l√®s',\n",
       " 'l‚Äô',\n",
       " \"m'\",\n",
       " 'ma',\n",
       " 'maint',\n",
       " 'maintenant',\n",
       " 'mais',\n",
       " 'malgre',\n",
       " 'malgr√©',\n",
       " 'me',\n",
       " 'meme',\n",
       " 'memes',\n",
       " 'merci',\n",
       " 'mes',\n",
       " 'mien',\n",
       " 'mienne',\n",
       " 'miennes',\n",
       " 'miens',\n",
       " 'mille',\n",
       " 'moi',\n",
       " 'moi-meme',\n",
       " 'moi-m√™me',\n",
       " 'moindres',\n",
       " 'moins',\n",
       " 'mon',\n",
       " 'm√™me',\n",
       " 'm√™mes',\n",
       " 'm‚Äô',\n",
       " \"n'\",\n",
       " 'na',\n",
       " 'ne',\n",
       " 'neanmoins',\n",
       " 'neuvi√®me',\n",
       " 'ni',\n",
       " 'nombreuses',\n",
       " 'nombreux',\n",
       " 'nos',\n",
       " 'notamment',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'nous-m√™mes',\n",
       " 'nouveau',\n",
       " 'nul',\n",
       " 'n√©anmoins',\n",
       " 'n√¥tre',\n",
       " 'n√¥tres',\n",
       " 'n‚Äô',\n",
       " 'o',\n",
       " 'on',\n",
       " 'ont',\n",
       " 'onze',\n",
       " 'onzi√®me',\n",
       " 'or',\n",
       " 'ou',\n",
       " 'ouias',\n",
       " 'ouste',\n",
       " 'outre',\n",
       " 'ouvert',\n",
       " 'ouverte',\n",
       " 'ouverts',\n",
       " 'o√π',\n",
       " 'par',\n",
       " 'parce',\n",
       " 'parfois',\n",
       " 'parle',\n",
       " 'parlent',\n",
       " 'parler',\n",
       " 'parmi',\n",
       " 'partant',\n",
       " 'pas',\n",
       " 'pendant',\n",
       " 'pense',\n",
       " 'permet',\n",
       " 'personne',\n",
       " 'peu',\n",
       " 'peut',\n",
       " 'peuvent',\n",
       " 'peux',\n",
       " 'plus',\n",
       " 'plusieurs',\n",
       " 'plutot',\n",
       " 'plut√¥t',\n",
       " 'possible',\n",
       " 'possibles',\n",
       " 'pour',\n",
       " 'pourquoi',\n",
       " 'pourrais',\n",
       " 'pourrait',\n",
       " 'pouvait',\n",
       " 'prealable',\n",
       " 'precisement',\n",
       " 'premier',\n",
       " 'premi√®re',\n",
       " 'premi√®rement',\n",
       " 'pres',\n",
       " 'procedant',\n",
       " 'proche',\n",
       " 'pr√®s',\n",
       " 'pr√©alable',\n",
       " 'pr√©cisement',\n",
       " 'pu',\n",
       " 'puis',\n",
       " 'puisque',\n",
       " \"qu'\",\n",
       " 'quand',\n",
       " 'quant',\n",
       " 'quant-√†-soi',\n",
       " 'quarante',\n",
       " 'quatorze',\n",
       " 'quatre',\n",
       " 'quatre-vingt',\n",
       " 'quatri√®me',\n",
       " 'quatri√®mement',\n",
       " 'que',\n",
       " 'quel',\n",
       " 'quelconque',\n",
       " 'quelle',\n",
       " 'quelles',\n",
       " \"quelqu'un\",\n",
       " 'quelque',\n",
       " 'quelques',\n",
       " 'quels',\n",
       " 'qui',\n",
       " 'quiconque',\n",
       " 'quinze',\n",
       " 'quoi',\n",
       " 'quoique',\n",
       " 'qu‚Äô',\n",
       " 'relative',\n",
       " 'relativement',\n",
       " 'rend',\n",
       " 'rendre',\n",
       " 'restant',\n",
       " 'reste',\n",
       " 'restent',\n",
       " 'retour',\n",
       " 'revoici',\n",
       " 'revoila',\n",
       " 'revoil√†',\n",
       " \"s'\",\n",
       " 'sa',\n",
       " 'sait',\n",
       " 'sans',\n",
       " 'sauf',\n",
       " 'se',\n",
       " 'seize',\n",
       " 'selon',\n",
       " 'semblable',\n",
       " 'semblaient',\n",
       " 'semble',\n",
       " 'semblent',\n",
       " 'sent',\n",
       " 'sept',\n",
       " 'septi√®me',\n",
       " 'sera',\n",
       " 'seraient',\n",
       " 'serait',\n",
       " 'seront',\n",
       " 'ses',\n",
       " 'seul',\n",
       " 'seule',\n",
       " 'seulement',\n",
       " 'seules',\n",
       " 'seuls',\n",
       " 'si',\n",
       " 'sien',\n",
       " 'sienne',\n",
       " 'siennes',\n",
       " 'siens',\n",
       " 'sinon',\n",
       " 'six',\n",
       " 'sixi√®me',\n",
       " 'soi',\n",
       " 'soi-meme',\n",
       " 'soi-m√™me',\n",
       " 'soit',\n",
       " 'soixante',\n",
       " 'son',\n",
       " 'sont',\n",
       " 'sous',\n",
       " 'souvent',\n",
       " 'specifique',\n",
       " 'specifiques',\n",
       " 'sp√©cifique',\n",
       " 'sp√©cifiques',\n",
       " 'stop',\n",
       " 'suffisant',\n",
       " 'suffisante',\n",
       " 'suffit',\n",
       " 'suis',\n",
       " 'suit',\n",
       " 'suivant',\n",
       " 'suivante',\n",
       " 'suivantes',\n",
       " 'suivants',\n",
       " 'suivre',\n",
       " 'sur',\n",
       " 'surtout',\n",
       " 's‚Äô',\n",
       " \"t'\",\n",
       " 'ta',\n",
       " 'tant',\n",
       " 'te',\n",
       " 'tel',\n",
       " 'telle',\n",
       " 'tellement',\n",
       " 'telles',\n",
       " 'tels',\n",
       " 'tenant',\n",
       " 'tend',\n",
       " 'tenir',\n",
       " 'tente',\n",
       " 'tes',\n",
       " 'tien',\n",
       " 'tienne',\n",
       " 'tiennes',\n",
       " 'tiens',\n",
       " 'toi',\n",
       " 'toi-meme',\n",
       " 'toi-m√™me',\n",
       " 'ton',\n",
       " 'touchant',\n",
       " 'toujours',\n",
       " 'tous',\n",
       " 'tout',\n",
       " 'toute',\n",
       " 'toutes',\n",
       " 'treize',\n",
       " 'trente',\n",
       " 'tres',\n",
       " 'trois',\n",
       " 'troisi√®me',\n",
       " 'troisi√®mement',\n",
       " 'tr√®s',\n",
       " 'tu',\n",
       " 't√©',\n",
       " 't‚Äô',\n",
       " 'un',\n",
       " 'une',\n",
       " 'unes',\n",
       " 'uns',\n",
       " 'va',\n",
       " 'vais',\n",
       " 'vas',\n",
       " 'vers',\n",
       " 'via',\n",
       " 'vingt',\n",
       " 'voici',\n",
       " 'voila',\n",
       " 'voil√†',\n",
       " 'vont',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'votres',\n",
       " 'vous',\n",
       " 'vous-m√™mes',\n",
       " 'vu',\n",
       " 'v√©',\n",
       " 'v√¥tre',\n",
       " 'v√¥tres',\n",
       " 'y',\n",
       " '√†',\n",
       " '√¢',\n",
       " '√ßa',\n",
       " '√®s',\n",
       " '√©galement',\n",
       " '√©taient',\n",
       " '√©tais',\n",
       " '√©tait',\n",
       " '√©tant',\n",
       " '√™tre',\n",
       " '√¥'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temmenized_root[temmenized_root['sender_name']=='Robin Goutard'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-anime",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
